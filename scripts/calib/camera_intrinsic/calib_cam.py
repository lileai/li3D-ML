#!/usr/bin/env python3
"""
å•ç›®ç›¸æœºæ ‡å®šè„šæœ¬ï¼ˆå¸¦å¯è§†åŒ– & å®æ—¶è¾“å‡º & PDF æŠ¥å‘Šï¼‰
ç”¨æ³•:
    python calib_cam.py --img_dir ./data/hik --pdf_report
"""
import cv2, numpy as np, json, os, shutil, argparse
from pathlib import Path
import io
import matplotlib.pyplot as plt
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.utils import ImageReader
from sklearn.model_selection import ShuffleSplit


# -------------------- å‚æ•°è§£æ --------------------
def parse_args():
    data_path = r"../../../data/calib/camera_intrinsic/data/jiaxing_capture"
    parser = argparse.ArgumentParser()
    parser.add_argument('--img_dir', default=data_path, type=str, help="æ ‡å®šå›¾åƒæ–‡ä»¶å¤¹")
    parser.add_argument('--out_dir', default=rf"{data_path}/output", help="è¾“å‡ºçš„è·¯å¾„")
    parser.add_argument('--w', default=12, type=int, help="æ ‡å®šæ¿æ¨ªå‘è§’ç‚¹æ•°")
    parser.add_argument('--h', default=10, type=int, help="æ ‡å®šæ¿çºµå‘è§’ç‚¹æ•°")
    parser.add_argument('--square_size', default=52, type=float, help="æ–¹æ ¼è¾¹é•¿(mm)")
    parser.add_argument('--min_images', default=15, type=int, help="æœ€å°‘æœ‰æ•ˆå›¾åƒæ•°")
    parser.add_argument('--max_reproj_err', default=0.7, type=float, help="æœ€å¤§å…è®¸é‡æŠ•å½±è¯¯å·®")
    parser.add_argument('--pdf_report', default=True, help="æ ‡å®šåç”Ÿæˆ PDF æŠ¥å‘Š")
    return parser.parse_args()


# -------------------- å·¥å…·å‡½æ•° --------------------
def collect_images(root):
    exts = ('*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif')
    files = []
    for ext in exts:
        files.extend(Path(root).rglob(ext))
    return sorted(files)


def compute_sharpness(gray):
    return cv2.Laplacian(gray, cv2.CV_64F).var()


def compute_brightness(gray):
    return np.mean(gray)


def validate_corner_layout(corners, pattern_size):
    return len(corners) == pattern_size[0] * pattern_size[1]


# -------------------- å›¾åƒç­›é€‰ & è§’ç‚¹æ£€æµ‹ --------------------
def select_and_show(images, pattern_size, args):
    selected, objpoints, imgpoints = [], [], []
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 500, 1e-6)
    objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)
    objp *= args.square_size
    total, valid = 0, 0
    for p in images:
        total += 1
        img = cv2.imread(str(p))
        if img is None:
            print(f"æ— æ³•è¯»å– {p.name}")
            continue
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)
        gray = cv2.GaussianBlur(gray, (3, 3), 0)
        sharpness = compute_sharpness(gray)
        brightness = compute_brightness(gray)
        if sharpness < 50:
            print(f"æ¸…æ™°åº¦ä½: {p.name} (sharpness={sharpness:.1f})")
            continue
        if brightness < 40 or brightness > 220:
            print(f"æ›å…‰å¼‚å¸¸: {p.name} (brightness={brightness:.1f})")
            continue
        flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK
        ret, corners = cv2.findChessboardCorners(gray, pattern_size, flags)
        if not ret:
            print(f"âŒ æœªæ£€æµ‹åˆ°æ ‡å®šæ¿: {p.name}")
            continue
        cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        if not validate_corner_layout(corners, pattern_size):
            print(f"âŒ è§’ç‚¹å¸ƒå±€å¼‚å¸¸: {p.name}")
            continue
        selected.append(p)
        objpoints.append(objp)
        imgpoints.append(corners)
        valid += 1
        vis = img.copy()
        cv2.drawChessboardCorners(vis, pattern_size, corners, ret)
        cv2.putText(vis, f"Sharp: {sharpness:.1f}, Bright: {brightness:.1f}",
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
        cv2.imshow("Calibration - Use ESC to exit", vis)
        if cv2.waitKey(500) == 27:
            break
    cv2.destroyAllWindows()
    print(f"\nğŸ“Š æ€»è®¡ {total} å¼  | æœ‰æ•ˆ {valid} å¼  | é€‰ä¸­ {len(selected)} å¼ ")
    img_size = gray.shape[::-1] if selected else None
    return selected, objpoints, imgpoints, img_size


# -------------------- é‡æŠ•å½±è¯¯å·® --------------------
def compute_reprojection_errors(objpoints, imgpoints, rvecs, tvecs, K, D):
    errors = []
    for i in range(len(objpoints)):
        proj_pts, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], K, D)
        err = cv2.norm(imgpoints[i], proj_pts, cv2.NORM_L2) / len(proj_pts)
        errors.append(err)
    return np.array(errors)


# -------------------- æ ‡å®šä¸»æµç¨‹ --------------------
def calibrate(selected, objpoints, imgpoints, img_size, square_size, args):
    new_obj = [o * square_size for o in objpoints]
    ret, K, D, rvecs, tvecs = cv2.calibrateCamera(
        new_obj, imgpoints, img_size, None, None,
        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 500, 1e-10))
    mean_error = compute_reprojection_errors(new_obj, imgpoints, rvecs, tvecs, K, D)
    print(f"åˆå§‹å¹³å‡é‡æŠ•å½±è¯¯å·®ï¼ˆMAEï¼‰: {mean_error.mean():.4f} åƒç´ ")
    if len(selected) > args.min_images:
        filtered_indices = [i for i, err in enumerate(mean_error) if err < args.max_reproj_err]
        if len(filtered_indices) >= args.min_images:
            objpoints = [objpoints[i] for i in filtered_indices]
            imgpoints = [imgpoints[i] for i in filtered_indices]
            print(f"é‡æ–°æ ‡å®šï¼Œä½¿ç”¨ {len(filtered_indices)} å¼ é«˜è´¨é‡å›¾åƒ")
            ret, K, D, rvecs, tvecs = cv2.calibrateCamera(
                objpoints, imgpoints, img_size, None, None,
                criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 500, 1e-10))
    return K, D, ret, rvecs, tvecs, objpoints, imgpoints


# -------------------- ä¿å­˜ & å»ç•¸å˜ --------------------
def save_selected(selected, out_dir):
    shutil.rmtree(out_dir, ignore_errors=True)
    os.makedirs(out_dir, exist_ok=True)
    for p in selected:
        shutil.copy2(str(p), out_dir)


def undistort(selected, K, D, out_dir):
    shutil.rmtree(out_dir, ignore_errors=True)
    os.makedirs(out_dir, exist_ok=True)
    for p in selected:
        img = cv2.imread(str(p))
        und = cv2.undistort(img, K, D)
        cv2.imwrite(str(Path(out_dir) / p.name), und)


def save_intrinsic(K, D, img_size, file='intrinsic.json'):
    # è·å–æ–‡ä»¶çš„çˆ¶ç›®å½•è·¯å¾„
    dir_path = os.path.dirname(file)
    # å¦‚æœçˆ¶ç›®å½•è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒ
    if dir_path and not os.path.exists(dir_path):
        os.makedirs(dir_path)
    data = {"K": K.tolist(), "dist": D[0].tolist(), "img_size": [img_size[0], img_size[1]]}
    with open(file, 'w') as f:
        json.dump(data, f, indent=2)
    print(f"å†…å‚å·²ä¿å­˜åˆ° {file}")


# -------------------- PDF æŠ¥å‘Š --------------------
def plot_reproj_error_heatmap(objpoints, imgpoints, rvecs, tvecs, K, D, img_size):
    all_proj_pts, all_img_pts = [], []
    for i in range(len(objpoints)):
        proj_pts, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], K, D)
        all_proj_pts.extend(proj_pts.reshape(-1, 2))
        all_img_pts.extend(imgpoints[i].reshape(-1, 2))
    all_proj_pts = np.array(all_proj_pts)
    all_img_pts = np.array(all_img_pts)
    errors = np.linalg.norm(all_proj_pts - all_img_pts, axis=1)

    plt.rcParams['font.family'] = 'SimSun'  # Windows å®‹ä½“
    plt.figure(figsize=(6, 4))
    plt.scatter(all_img_pts[:, 0], all_img_pts[:, 1], c=errors, cmap='jet', s=8)
    plt.colorbar(label='è¯¯å·®ï¼ˆåƒç´ ï¼‰')
    plt.title("é‡æŠ•å½±è¯¯å·®çƒ­åŠ›å›¾")
    plt.xlabel("X åƒç´ ")
    plt.ylabel("Y åƒç´ ")
    plt.gca().invert_yaxis()
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    plt.close()
    return buf


def robust_test_focal_variation(selected, objpoints, imgpoints, img_size):
    ss = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)
    fs = []
    for train_idx, _ in ss.split(selected):
        obj_tr = [objpoints[i] for i in train_idx]
        img_tr = [imgpoints[i] for i in train_idx]
        _, K, _, _, _ = cv2.calibrateCamera(obj_tr, img_tr, img_size, None, None)
        fs.append(K[0, 0])
    return np.std(fs) / np.mean(fs) * 100


def generate_pdf_report(K, D, img_size, selected, errors, rvecs, tvecs, objpoints, imgpoints, path):
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    # æ³¨å†Œä¸­æ–‡å­—ä½“
    try:
        pdfmetrics.registerFont(TTFont('song', 'simsun.ttc'))
        song = 'song'
    except:
        pdfmetrics.registerFont(TTFont('song', '/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf'))
        song = 'song'

    c = canvas.Canvas(path, pagesize=A4)
    w, h = A4

    # æ ‡é¢˜
    c.setFont(song, 18)
    c.drawString(50, h - 50, "ç›¸æœºæ ‡å®šæŠ¥å‘Š")

    # æ­£æ–‡
    c.setFont(song, 11)
    y = h - 90
    c.drawString(50, y, f"â—  å›¾åƒæ•°é‡ï¼š{len(selected)} å¼ ")
    y -= 20
    c.drawString(50, y, f"â—  å¹³å‡é‡æŠ•å½±è¯¯å·®ï¼š{np.mean(errors):.3f} åƒç´ ")
    y -= 20
    c.drawString(50, y, f"â—  è¯¯å·®æ ‡å‡†å·®ï¼š{np.std(errors):.3f} åƒç´ ")
    y -= 20
    c.drawString(50, y, f"â—  æœ€å¤§è¯¯å·®ï¼š{np.max(errors):.3f} åƒç´ ")
    y -= 20
    c.drawString(50, y, f"â—  ç„¦è· fxï¼š{K[0, 0]:.2f} åƒç´ ")
    y -= 20
    c.drawString(50, y, f"â—  ä¸»ç‚¹åç§»ï¼š({abs(K[0, 2] - img_size[0] / 2):.1f}, {abs(K[1, 2] - img_size[1] / 2):.1f}) åƒç´ ")
    y -= 20
    # âœ… ç•¸å˜åˆç†æ€§ï¼šå¤šç•™ 50 åƒç´ å®‰å…¨åŒº
    c.drawString(50, y, f"â—  ç•¸å˜ç³»æ•°åˆç†æ€§ï¼š{'åˆæ ¼' if all(abs(d) < 0.5 for d in D[0][:4]) else 'å¼‚å¸¸'}")
    y -= 50          # â† å®‰å…¨é—´è·
    c.drawString(50, y, "â—  é‡æŠ•å½±è¯¯å·®çƒ­åŠ›å›¾ï¼š")
    y -= 10          # å†ç•™ä¸€ç‚¹ç©ºç™½

    # âœ… å…ˆç”Ÿæˆå›¾ç‰‡ï¼Œå†è´´å›¾ï¼ˆé¡ºåºé åï¼‰
    heatmap_buf = plot_reproj_error_heatmap(objpoints, imgpoints, rvecs, tvecs, K, D, img_size)
    c.drawImage(ImageReader(heatmap_buf), 50, y - 260, width=400, height=260)
    y -= 280

    # é²æ£’æ€§
    focal_var = robust_test_focal_variation(selected, objpoints, imgpoints, img_size)
    c.drawString(50, y, f"â—  é²æ£’æ€§æµ‹è¯•ï¼ˆç„¦è·æ³¢åŠ¨ï¼‰ï¼š{focal_var:.2f} %")
    if focal_var > 3:
        c.drawString(50, y - 20, "âš ï¸  è­¦å‘Šï¼šå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ å›¾åƒæ•°é‡æˆ–å¤šæ ·æ€§ï¼")

    y -= 40  # ä¸ä¸Šä¸€æ®µç•™ç‚¹ç©º

    # ------------------------------------------------------------------
    # 1. è®¡ç®— 5 é¡¹å­åˆ†ï¼ˆ0â€“100ï¼‰
    # ------------------------------------------------------------------
    n_img = len(selected)
    mean_e = np.mean(errors)
    std_e = np.std(errors)
    max_e = np.max(errors)
    foc_var = focal_var

    # 1.1 å›¾åƒæ•°é‡åˆ†ï¼ˆ10 å¼ â†’100 åˆ†ï¼Œçº¿æ€§æ’å€¼ï¼Œæœ€å¤š 100ï¼‰
    score_n = min(100., n_img * 10.)

    # 1.2 å¹³å‡è¯¯å·®åˆ†ï¼ˆ0.05 pxâ†’100 åˆ†ï¼Œ0.5 pxâ†’0 åˆ†ï¼Œçº¿æ€§ï¼‰
    score_mean = max(0., 100 * (0.5 - mean_e) / 0.45)

    # 1.3 è¯¯å·®æ ‡å‡†å·®åˆ†ï¼ˆ0.02 pxâ†’100 åˆ†ï¼Œ0.3 pxâ†’0 åˆ†ï¼‰
    score_std = max(0., 100 * (0.3 - std_e) / 0.28)

    # 1.4 æœ€å¤§è¯¯å·®åˆ†ï¼ˆ0.1 pxâ†’100 åˆ†ï¼Œ2 pxâ†’0 åˆ†ï¼‰
    score_max = max(0., 100 * (2.0 - max_e) / 1.9)

    # 1.5 é²æ£’æ€§åˆ†ï¼ˆç„¦è·æ³¢åŠ¨ 0 %â†’100 åˆ†ï¼Œ5 %â†’0 åˆ†ï¼‰
    score_var = max(0., 100 * (5.0 - foc_var) / 5.0)

    # ------------------------------------------------------------------
    # 2. åŠ æƒç»¼åˆï¼ˆæƒé‡å¯è‡ªå·±è°ƒï¼‰
    # ------------------------------------------------------------------
    weights = np.array([0.10, 0.30, 0.20, 0.20, 0.20])  # é¡ºåºå¯¹åº”ä¸Šé¢ 5 é¡¹
    scores = np.array([score_n, score_mean, score_std, score_max, score_var])
    total = float(np.dot(weights, scores))

    # ------------------------------------------------------------------
    # 3. ç”»åˆ° PDF
    # ------------------------------------------------------------------
    c.setFont(song, 14)
    c.drawString(50, y, "â—  ç»¼åˆè¯„åˆ†ï¼š")
    y -= 30

    # ç”»ä¸€ä¸ªé†’ç›®è‰²å—
    box_w, box_h = 120, 50
    c.setFillColorRGB(0.13, 0.55, 0.13)  # æ·±ç»¿
    c.rect(50, y - box_h, box_w, box_h, fill=1)

    # åœ¨è‰²å—ä¸­å¤®å†™ç™½å­—
    c.setFillColorRGB(1, 1, 1)
    c.setFont(song, 28)
    c.drawCentredString(50 + box_w / 2, y - box_h + 12, f"{total:.0f}")

    c.save()
    print(f"ğŸ“„ ä¸­æ–‡ PDF æŠ¥å‘Šå·²ä¿å­˜ï¼š{path}")


# -------------------- main --------------------
def main():
    args = parse_args()
    images = collect_images(Path(args.img_dir))
    if not images:
        print("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
        return
    selected, objp, imgp, img_size = select_and_show(images, (args.w, args.h), args)
    if len(selected) < 5:
        print("æœ‰æ•ˆå›¾ç‰‡ä¸è¶³ 5 å¼ ï¼Œæ ‡å®šç»ˆæ­¢")
        return
    K, D, err, rvecs, tvecs, objp, imgp = calibrate(selected, objp, imgp, img_size, args.square_size, args)
    print(f"ğŸ“ é‡æŠ•å½±è¯¯å·®(RMS): {err:.4f} åƒç´ ")
    save_selected(selected, f'{args.img_dir}/selected')
    undistort(selected, K, D, f'{args.img_dir}/undistorted')
    save_intrinsic(K, D, img_size, f'{args.out_dir}/intrinsic.json')

    if args.pdf_report:
        errors = compute_reprojection_errors(objp, imgp, rvecs, tvecs, K, D)
        generate_pdf_report(K, D, img_size, selected, errors, rvecs, tvecs, objp, imgp,
                            path=f'{args.out_dir}/calibration_report.pdf')


if __name__ == '__main__':
    main()
